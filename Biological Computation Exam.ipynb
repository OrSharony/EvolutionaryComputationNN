{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import logging\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from random import uniform as randnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "\n",
    "def logistic(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def logistic_derivative(x):\n",
    "    return logistic(x)*(1-logistic(x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "activation_funcs = {\n",
    "    'relu': relu,\n",
    "    'tanh': tanh,\n",
    "    'logistic': logistic\n",
    "}\n",
    "\n",
    "der_activation_funcs = {\n",
    "    'relu': relu_derivative,\n",
    "    'tanh': tanh_derivative,\n",
    "    'logistic': logistic_derivative\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class GANetwork(object):\n",
    "\n",
    "    def __init__(self, net_architecture, activation):\n",
    "        \n",
    "        self.num_layers = len(net_architecture)\n",
    "        self.net_architecture = net_architecture\n",
    "        self.biases = [np.random.randn(y, 1) for y in net_architecture[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(net_architecture[:-1], net_architecture[1:])]\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.bias_nitem = sum(net_architecture[1:])\n",
    "        self.weight_nitem = sum([self.weights[i].size for i in range(self.num_layers-2)])\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = activation_funcs[self.activation](np.dot(w,a)+b)\n",
    "        return a\n",
    "\n",
    "    def get_biases_count(self):\n",
    "        return sum(self.net_architecture[1:])\n",
    "    \n",
    "    def get_weights_count(self):\n",
    "        return sum([self.weights[i].size for i in range(self.num_layers-2)])\n",
    "    \n",
    "    def get_error(self, X, y):\n",
    "        total_error=0\n",
    "        for i in range(X.shape[0]):\n",
    "            predicted = self.feedforward(X[i].reshape(-1,1))\n",
    "            actual = y[i].reshape(-1,1)\n",
    "            total_error += np.sum(np.power(predicted-actual,2)/2)  # mean-squared error\n",
    "        return total_error\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        accuracy = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            output = self.feedforward(X[i].reshape(-1,1))\n",
    "            accuracy += int(np.argmax(output) == np.argmax(y[i]))\n",
    "        return accuracy / X.shape[0] * 100\n",
    "\n",
    "class NNGeneticAlgo:\n",
    "\n",
    "    def __init__(self, n_pops, net_size, activation, mutation_rate, crossover_rate, retain_rate, X, y):\n",
    "        self.n_pops = n_pops\n",
    "        self.net_size = net_size\n",
    "        self.nets = [GANetwork(self.net_size, activation) for i in range(self.n_pops)]\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.retain_rate = retain_rate\n",
    "        self.X = X[:]\n",
    "        self.y = y[:]\n",
    "    \n",
    "    def get_random_point(self, type):\n",
    "        net = self.nets[0]\n",
    "        layer_index, point_index = random.randint(0, net.num_layers-2), 0\n",
    "        if type == 'weight':\n",
    "            row = random.randint(0,net.weights[layer_index].shape[0]-1)\n",
    "            col = random.randint(0,net.weights[layer_index].shape[1]-1)\n",
    "            point_index = (row, col)\n",
    "        elif type == 'bias':\n",
    "            point_index = random.randint(0,net.biases[layer_index].size-1)\n",
    "        return (layer_index, point_index)\n",
    "\n",
    "    def get_all_errors(self):\n",
    "        return [net.get_error(self.X, self.y) for net in self.nets]\n",
    "\n",
    "    def get_all_accuracies(self):\n",
    "        return [(net, net.accuracy(self.X, self.y)) for net in self.nets]\n",
    "\n",
    "    def crossover(self, father, mother):\n",
    "        # take the father 'genetic'\n",
    "        net = copy.deepcopy(father)\n",
    "        # cross-over biases\n",
    "        for _ in range(self.nets[0].get_biases_count()): \n",
    "            if random.uniform(0,1) < self.crossover_rate:\n",
    "                layer, point = self.get_random_point('bias')\n",
    "                net.biases[layer][point] = mother.biases[layer][point]\n",
    "        # cross-over weights\n",
    "        for _ in range(self.nets[0].get_weights_count()):\n",
    "            if random.uniform(0,1) < self.crossover_rate:\n",
    "                layer, point = self.get_random_point('weight')\n",
    "                net.weights[layer][point] = mother.weights[layer][point]\n",
    "        return net\n",
    "        \n",
    "    def mutation(self, child):\n",
    "        net = copy.deepcopy(child)\n",
    "        # mutate biases\n",
    "        for _ in range(self.nets[0].get_biases_count()):\n",
    "            if random.uniform(0,1) < self.mutation_rate:\n",
    "                layer, point = self.get_random_point('bias')\n",
    "                net.biases[layer][point] += random.uniform(-0.5, 0.5)\n",
    "        # mutate weights\n",
    "        for _ in range(self.nets[0].get_weights_count()):\n",
    "            if random.uniform(0,1) < self.mutation_rate:\n",
    "                layer, point = self.get_random_point('weight')\n",
    "                net.weights[layer][point[0], point[1]] += random.uniform(-0.5, 0.5)\n",
    "        return net\n",
    "\n",
    "    def evolve(self):\n",
    "        score_list = list(zip(self.nets, self.get_all_errors()))\n",
    "        score_list.sort(key=lambda x: x[1])\n",
    "        score_list = [obj[0] for obj in score_list]\n",
    "        retain_num = int(self.n_pops*self.retain_rate)\n",
    "        score_list_top = score_list[:retain_num]\n",
    "        retain_non_best = int((self.n_pops-retain_num) * self.retain_rate)\n",
    "        for _ in range(random.randint(0, retain_non_best)):\n",
    "            score_list_top.append(random.choice(score_list[retain_num:]))\n",
    "\n",
    "        # breed new childs if current population number less than the population size\n",
    "        while len(score_list_top) < self.n_pops:\n",
    "            father = random.choice(score_list_top)\n",
    "            mother = random.choice(score_list_top)\n",
    "            if father != mother:\n",
    "                new_child = self.crossover(father, mother)\n",
    "                new_child = self.mutation(new_child)\n",
    "                score_list_top.append(new_child)\n",
    "        \n",
    "        self.nets = score_list_top\n",
    "\n",
    "def trainer(net_arcitecture, activation, X, y, input_shape, num_of_classes, X_test, y_test):\n",
    "    y = y.reshape(-1, 1)\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(y)\n",
    "    y = enc.transform(y).toarray()\n",
    "\n",
    "    n_generations = 180\n",
    "    n_populations = 22 \n",
    "    net_size = copy.deepcopy(net_arcitecture)\n",
    "    net_size.insert(0,input_shape)\n",
    "    net_size.append(num_of_classes)\n",
    "\n",
    "    mutation_rate = 0.2\n",
    "    crossover_rate = 0.4\n",
    "    retain_rate = 0.4\n",
    "\n",
    "    # start our neural-net & optimize it using genetic algorithm\n",
    "    nnga = NNGeneticAlgo(n_populations, net_size, activation, mutation_rate, crossover_rate , retain_rate, X, y)\n",
    "    start_time = time.time()\n",
    "    the_best = 0\n",
    " \n",
    "    print('-' * 80)\n",
    "    for i in range(n_generations):\n",
    "        if i % 10 == 0:\n",
    "            print(\"Current iteration : {}\".format(i+1))\n",
    "            accuracies = nnga.get_all_accuracies()\n",
    "            the_best = sorted(accuracies, key=lambda x: x[1], reverse=True)[0]\n",
    "            print(\"Current top member's network accuracy: %.2f%%\\n\" %  the_best[1])\n",
    "        nnga.evolve()\n",
    "        \n",
    "    return the_best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNetwork():\n",
    "\n",
    "    def __init__(self, num_layers, neurons_in_layer, input_shape, num_of_classes, activation):\n",
    "        self._num_layers = num_layers + 2  # for the input and output layer\n",
    "        self._neurons_in_layer = copy.deepcopy(neurons_in_layer)\n",
    "        self._neurons_in_layer.insert(0,input_shape)\n",
    "        self._neurons_in_layer.append(num_of_classes)\n",
    "        self._activation_func = activation\n",
    "        \n",
    "        self._weights = []\n",
    "        for l in range(self._num_layers - 1):\n",
    "            self._weights.append([])\n",
    "            for i in range(self._neurons_in_layer[l]):\n",
    "                self._weights[l].append([])\n",
    "                for j in range(self._neurons_in_layer[l+1]):\n",
    "                    self._weights[l][i].append(randnum(-1, 1))\n",
    "\n",
    "        self._biases = [None]\n",
    "        for l in range(1, self._num_layers):\n",
    "            self._biases.append([])\n",
    "            for i in range(self._neurons_in_layer[l]):\n",
    "                self._biases[l].append(randnum(-1, 1))\n",
    "\n",
    "    def FeedForward(self, inputs):\n",
    "        if len(inputs) != self._neurons_in_layer[0]:\n",
    "            raise InputSizeError()\n",
    "\n",
    "        self._activations = [inputs]\n",
    "        self._weighted_inputs = [None]\n",
    "        for l in range(1, self._num_layers):\n",
    "            self._activations.append([])\n",
    "            self._weighted_inputs.append([])\n",
    "            for i in range(self._neurons_in_layer[l]):\n",
    "                weighted_input = 0\n",
    "                for h in range(self._neurons_in_layer[l-1]):\n",
    "                    weighted_input += (self._activations[l-1][h] *\n",
    "                                       self._weights[l-1][h][i])\n",
    "                self._weighted_inputs[l].append(weighted_input)\n",
    "                weighted_input += self._biases[l][i]\n",
    "                self._activations[l].append(activation_funcs[self._activation_func](weighted_input))\n",
    "        # Return the last layer of activations\n",
    "        return self._activations[self._num_layers - 1]\n",
    "\n",
    "    \n",
    "    def Train(self, inputs_set, expected_set, learning_rate, X_test, y_test):\n",
    "        expected_set = expected_set.reshape(-1, 1)\n",
    "        enc = OneHotEncoder()\n",
    "        enc.fit(expected_set)\n",
    "        expected_set = enc.transform(expected_set).toarray()\n",
    "        \n",
    "        for _ in range(100):\n",
    "            # Back propogation\n",
    "            for t in range(len(inputs_set)):\n",
    "                inputs = inputs_set[t]\n",
    "                expected = expected_set[t]\n",
    "                if len(inputs) != self._neurons_in_layer[0]:\n",
    "                    raise InputSizeError()\n",
    "                if len(expected) != self._neurons_in_layer[self._num_layers - 1]:\n",
    "                    raise InputSizeError()\n",
    "                \n",
    "                self.FeedForward(inputs)\n",
    "                errors = [None]\n",
    "                for l in range(1, self._num_layers):\n",
    "                    errors.append([])\n",
    "                # Calculate the errors in the output layer\n",
    "                for i in range(self._neurons_in_layer[self._num_layers - 1]):\n",
    "                    error = (self._activations[self._num_layers - 1][i] -\n",
    "                             expected[i])\n",
    "                    error *= der_activation_funcs[self._activation_func](self._weighted_inputs[l][i])\n",
    "                    errors[self._num_layers - 1].append(error)\n",
    "                # Calculate the errors in the hidden layers\n",
    "                for l in range(self._num_layers - 2, 0, -1):\n",
    "                    for i in range(self._neurons_in_layer[l]):\n",
    "                        error = 0\n",
    "                        for j in range(self._neurons_in_layer[l+1]):\n",
    "                            error += self._weights[l][i][j] * errors[l+1][j]\n",
    "                        error *= der_activation_funcs[self._activation_func](self._weighted_inputs[l][i])\n",
    "                        errors[l].append(error)\n",
    "                # Update the biases for each neuron\n",
    "                for l in range(1, self._num_layers):\n",
    "                    for i in range(self._neurons_in_layer[l]):\n",
    "                        self._biases[l][i] -= learning_rate * errors[l][i]\n",
    "                # Update the weights for each neuron\n",
    "                for l in range(0, self._num_layers-1):\n",
    "                    for i in range(self._neurons_in_layer[l]):\n",
    "                        for j in range(self._neurons_in_layer[l+1]):\n",
    "                            self._weights[l][i][j] -= (learning_rate *\n",
    "                                                       self._activations[l][i] *\n",
    "                                                       errors[l+1][j])\n",
    "        correctness = 0\n",
    "        for indx, val in enumerate(X_test):\n",
    "            res = self.FeedForward(val)\n",
    "            res = res.index(max(res))\n",
    "            if res == y_test[indx]:\n",
    "                correctness += 1\n",
    "        \n",
    "        return correctness / len(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_alternatives = {\n",
    "    'num_of_neurons': 20,\n",
    "    'num_of_layers': 4,\n",
    "    #'activation': ['relu','identity', 'tanh', 'logistic'],\n",
    "    'activation': ['relu','tanh', 'logistic']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset_name):\n",
    "    input_shape = 0\n",
    "    if(dataset_name == 'iris'):\n",
    "        iris = datasets.load_iris()\n",
    "        X = iris.data\n",
    "        y = iris.target\n",
    "        nb_classes = 3\n",
    "        input_shape = 4\n",
    "    elif(dataset_name == 'digits'):\n",
    "        digits = datasets.load_digits()\n",
    "        X = digits.data\n",
    "        y = digits.target\n",
    "        nb_classes = 10\n",
    "        input_shape = 64\n",
    "    elif(dataset_name == 'wine'):\n",
    "        digits = datasets.load_wine()\n",
    "        X = digits.data\n",
    "        y = digits.target\n",
    "        nb_classes = 3\n",
    "        input_shape = 13\n",
    "\n",
    "    if(input_shape != 0):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "        return (nb_classes, input_shape, x_train, x_test, y_train, y_test)\n",
    "    \n",
    "\n",
    "def train_and_score(network, dataset, trainer_method):\n",
    "    num_of_layers = len(network['architecture'])\n",
    "    activation = network['activation']\n",
    "    architecture = network['architecture']\n",
    "\n",
    "    nb_classes, input_shape, x_train, x_test, y_train, y_test = get_data(dataset)\n",
    "    accur = None\n",
    "    \n",
    "    if trainer_method == 'GA':\n",
    "        #Use genetic algorithm\n",
    "        accur = trainer(architecture, activation, x_train, y_train, input_shape, nb_classes, x_test, y_test)\n",
    "    elif trainer_method == 'BP':\n",
    "        # Use back propogation algorithm\n",
    "        network = BPNetwork(num_of_layers, architecture, input_shape, nb_classes, activation)\n",
    "        accur = network.Train(x_train, y_train, 1, x_test, y_test)\n",
    "    elif trainer_method == 'MLP':\n",
    "        # Use MLPClassifier from sklearn\n",
    "        model = MLPClassifier(hidden_layer_sizes = architecture, activation = activation, learning_rate_init = 1, max_iter = 400, solver = 'lbfgs').fit(x_train, y_train)\n",
    "        accur = model.score(x_test, y_test)\n",
    "    \n",
    "    return accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.accuracy = 0.\n",
    "        self.network = {}\n",
    "\n",
    "    def create_random(self):\n",
    "        self.network['activation'] = random.choice(param_alternatives['activation'])\n",
    "        num_of_layers = random.randint(1, param_alternatives['num_of_layers'])\n",
    "        architecture = []\n",
    "        for _ in range(num_of_layers):\n",
    "            architecture.append(random.randint(1, param_alternatives['num_of_neurons']))\n",
    "        self.network['architecture'] = architecture\n",
    "    \n",
    "    def train(self, dataset, trainer_method):\n",
    "        if self.accuracy == 0.:\n",
    "            self.accuracy = train_and_score(self.network, dataset, trainer_method)\n",
    "\n",
    "    def print_network(self):\n",
    "        logging.info(self.network)\n",
    "        logging.info(\"Network accuracy: %.2f%%\" % (self.accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticOperations():\n",
    "    \n",
    "    def __init__(self, retain=0.4, random_select=0.1, mutate_chance=0.2):\n",
    "        self.mutate_chance = mutate_chance\n",
    "        self.random_select = random_select\n",
    "        self.retain = retain\n",
    "\n",
    "    def create_population(self, count):\n",
    "        pop = []\n",
    "        for _ in range(0, count):\n",
    "            network = Network()\n",
    "            network.create_random()\n",
    "            pop.append(network)\n",
    "        return pop\n",
    "\n",
    "    def fitness(self, network):\n",
    "        return network.accuracy\n",
    "\n",
    "    def grade(self, pop):\n",
    "        summed = reduce(add, (self.fitness(network) for network in pop))\n",
    "        return summed / float((len(pop)))\n",
    "\n",
    "    def breed(self, mother, father):\n",
    "        children = []\n",
    "        max_layers = param_alternatives['num_of_layers']\n",
    "        for _ in range(2):\n",
    "            child = {}\n",
    "            child['activation'] = random.choice([mother.network['activation'], father.network['activation']])\n",
    "            child['architecture'] = mother.network['architecture'][:len(mother.network['architecture'])//2] + \\\n",
    "                father.network['architecture'][len(father.network['architecture'])//2:]\n",
    "            \n",
    "            network = Network()\n",
    "            network.network = child\n",
    "\n",
    "            # randomly mutate some of the children.\n",
    "            if self.mutate_chance > random.random():\n",
    "                network = self.mutate(network)\n",
    "            children.append(network)\n",
    "\n",
    "        return children\n",
    "\n",
    "    def mutate(self, network):\n",
    "        # Choose a random key.\n",
    "        mutation = random.choice(['architecture', 'activation'])\n",
    "\n",
    "        # Mutate the selected key.\n",
    "        if mutation == 'activation':\n",
    "             network.network['activation'] = random.choice(param_alternatives['activation'])\n",
    "        else:\n",
    "            for i in range(2):\n",
    "                index = random.randint(0,len(network.network['architecture'])-1)\n",
    "                network.network['architecture'][index] = random.randint(1, param_alternatives['num_of_neurons'])\n",
    "        return network\n",
    "\n",
    "    def evolve(self, pop):\n",
    "        # Get scores for each network.\n",
    "        graded = [(self.fitness(network), network) for network in pop]\n",
    "        # Sorts the scores desceding.\n",
    "        graded = [x[1] for x in sorted(graded, key=lambda x: x[0], reverse=True)]\n",
    "        # Get the number we want to keep for the next generation.\n",
    "        retain_length = int(len(graded)*self.retain)\n",
    "        # The parents are every network we want to keep.\n",
    "        parents = graded[:retain_length]\n",
    "        # Randomly keep some of the rest networks\n",
    "        for individual in graded[retain_length:]:\n",
    "            if self.random_select > random.random():\n",
    "                parents.append(individual)\n",
    "\n",
    "        # fill the rest\n",
    "#         parents = list(set(parents))\n",
    "        parents_length = len(parents)\n",
    "        all_nets = [(net.network['architecture'], net.network['activation']) for net in parents]\n",
    "\n",
    "        desired_length = len(pop) - parents_length\n",
    "        children = []\n",
    "        while len(children) < desired_length:\n",
    "            male = random.randint(0, parents_length-1)\n",
    "            female = random.randint(0, parents_length-1)\n",
    "            if male != female:\n",
    "                male = parents[male]\n",
    "                female = parents[female]\n",
    "                babies = self.breed(male, female)\n",
    "                for baby in babies:\n",
    "                    if len(children) < desired_length:\n",
    "                        baby_net = (baby.network['architecture'], baby.network['activation'])\n",
    "                        if baby_net not in all_nets:\n",
    "                            children.append(baby)\n",
    "                            all_nets.append(baby_net)\n",
    "        parents.extend(list(children))\n",
    "        \n",
    "        print('The generation:')\n",
    "        print([(net.network['architecture'],net.network['activation'])  for net in parents])\n",
    "        return parents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 12:55:58 PM - INFO - ***Envolving generation 1 of 10***\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61833d849fc4467aad84f103e485206e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 01:02:54 PM - INFO - {'activation': 'logistic', 'architecture': [19, 7, 16]}\n",
      "04/30/2021 01:02:54 PM - INFO - Network accuracy: 97.78%\n",
      "04/30/2021 01:02:54 PM - INFO - {'activation': 'logistic', 'architecture': [14]}\n",
      "04/30/2021 01:02:54 PM - INFO - Network accuracy: 97.78%\n",
      "04/30/2021 01:02:54 PM - INFO - {'activation': 'logistic', 'architecture': [7, 5, 17]}\n",
      "04/30/2021 01:02:54 PM - INFO - Network accuracy: 97.78%\n",
      "04/30/2021 01:02:54 PM - INFO - {'activation': 'logistic', 'architecture': [13, 16, 20]}\n",
      "04/30/2021 01:02:54 PM - INFO - Network accuracy: 95.56%\n",
      "04/30/2021 01:02:54 PM - INFO - {'activation': 'logistic', 'architecture': [13, 15, 2]}\n",
      "04/30/2021 01:02:54 PM - INFO - Network accuracy: 88.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison to MLP from sklearn:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Or\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "04/30/2021 01:02:55 PM - INFO - Generation Average: 57.11%\n",
      "04/30/2021 01:02:55 PM - INFO - --------------------------------------------------------------------------------\n",
      "04/30/2021 01:02:55 PM - INFO - ***Envolving generation 2 of 10***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.9333333333333333\n",
      "The generation:\n",
      "[([19, 7, 16], 'logistic'), ([14], 'logistic'), ([7, 5, 17], 'logistic'), ([13, 16, 20], 'logistic'), ([13, 15, 2], 'logistic'), ([4, 10], 'logistic'), ([5], 'logistic'), ([6, 3, 6, 20], 'logistic'), ([7, 5], 'logistic'), ([6, 3, 5, 17], 'logistic'), ([13, 10], 'logistic'), ([15, 16], 'logistic'), ([16, 20], 'logistic'), ([13, 7, 16], 'logistic'), ([15, 2], 'logistic'), ([5, 17], 'logistic'), ([6, 20], 'logistic'), ([6, 3, 16, 20], 'logistic'), ([13, 5], 'logistic'), ([14, 20], 'logistic')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d951fa5d1c5142e385d05df42c594282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 01:08:03 PM - INFO - {'activation': 'logistic', 'architecture': [16, 20]}\n",
      "04/30/2021 01:08:03 PM - INFO - Network accuracy: 100.00%\n",
      "04/30/2021 01:08:03 PM - INFO - {'activation': 'logistic', 'architecture': [19, 7, 16]}\n",
      "04/30/2021 01:08:03 PM - INFO - Network accuracy: 97.78%\n",
      "04/30/2021 01:08:03 PM - INFO - {'activation': 'logistic', 'architecture': [14]}\n",
      "04/30/2021 01:08:03 PM - INFO - Network accuracy: 97.78%\n",
      "04/30/2021 01:08:03 PM - INFO - {'activation': 'logistic', 'architecture': [7, 5, 17]}\n",
      "04/30/2021 01:08:03 PM - INFO - Network accuracy: 97.78%\n",
      "04/30/2021 01:08:03 PM - INFO - {'activation': 'logistic', 'architecture': [13, 16, 20]}\n",
      "04/30/2021 01:08:03 PM - INFO - Network accuracy: 95.56%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison to MLP from sklearn:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Or\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "04/30/2021 01:08:04 PM - INFO - Generation Average: 80.67%\n",
      "04/30/2021 01:08:04 PM - INFO - --------------------------------------------------------------------------------\n",
      "04/30/2021 01:08:04 PM - INFO - ***Envolving generation 3 of 10***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.9333333333333333\n",
      "The generation:\n",
      "[([16, 20], 'logistic'), ([19, 7, 16], 'logistic'), ([14], 'logistic'), ([7, 5, 17], 'logistic'), ([13, 16, 20], 'logistic'), ([13, 7, 16], 'logistic'), ([5, 17], 'logistic'), ([13, 10], 'logistic'), ([6, 3, 6, 20], 'logistic'), ([6, 20], 'logistic'), ([13, 6, 20], 'logistic'), ([5, 5, 17], 'logistic'), ([6, 3, 7, 16], 'logistic'), ([16, 20, 17], 'logistic'), ([16, 7, 16], 'logistic'), ([10], 'logistic'), ([13, 14], 'logistic'), ([13, 10, 6], 'logistic'), ([5, 6, 6], 'logistic'), ([16, 6, 20], 'logistic')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104f918b6db94318a1303199f26774df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/30/2021 01:13:35 PM - INFO - {'activation': 'logistic', 'architecture': [16, 20]}\n",
      "04/30/2021 01:13:35 PM - INFO - Network accuracy: 100.00%\n",
      "04/30/2021 01:13:35 PM - INFO - {'activation': 'logistic', 'architecture': [19, 7, 16]}\n",
      "04/30/2021 01:13:35 PM - INFO - Network accuracy: 97.78%\n",
      "04/30/2021 01:13:35 PM - INFO - {'activation': 'logistic', 'architecture': [14]}\n",
      "04/30/2021 01:13:35 PM - INFO - Network accuracy: 97.78%\n",
      "04/30/2021 01:13:35 PM - INFO - {'activation': 'logistic', 'architecture': [7, 5, 17]}\n",
      "04/30/2021 01:13:35 PM - INFO - Network accuracy: 97.78%\n",
      "04/30/2021 01:13:35 PM - INFO - {'activation': 'logistic', 'architecture': [16, 20, 17]}\n",
      "04/30/2021 01:13:35 PM - INFO - Network accuracy: 97.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison to MLP from sklearn:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Or\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "04/30/2021 01:13:35 PM - INFO - Generation Average: 82.67%\n",
      "04/30/2021 01:13:35 PM - INFO - --------------------------------------------------------------------------------\n",
      "04/30/2021 01:13:35 PM - INFO - ***Envolving generation 4 of 10***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.9333333333333333\n",
      "The generation:\n",
      "[([16, 20], 'logistic'), ([19, 7, 16], 'logistic'), ([14], 'logistic'), ([7, 5, 17], 'logistic'), ([16, 20, 17], 'logistic'), ([13, 16, 20], 'logistic'), ([13, 7, 16], 'logistic'), ([5, 17], 'logistic'), ([7, 20], 'logistic'), ([5, 7, 16], 'logistic'), ([7, 20, 17], 'logistic'), ([19, 16, 20], 'logistic'), ([5, 20], 'logistic'), ([13, 17], 'logistic'), ([13, 14], 'logistic'), ([13, 5, 17], 'logistic'), ([13, 19, 4], 'logistic'), ([16, 17], 'logistic'), ([17], 'logistic'), ([17], 'relu')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a21296da0d477fa4c217043afc871b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "    level=logging.DEBUG\n",
    ")\n",
    "\n",
    "def train_networks(networks, dataset, trainer_method):\n",
    "    pbar = tqdm(total=len(networks))\n",
    "    for network in networks:\n",
    "        network.train(dataset, trainer_method)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "def get_average_accuracy(networks):\n",
    "    total_accuracy = 0\n",
    "    for network in networks:\n",
    "        total_accuracy += network.accuracy\n",
    "\n",
    "    return total_accuracy / len(networks)\n",
    "\n",
    "def generate(generations, population, dataset, trainer_method):\n",
    "\n",
    "    nb_classes, input_shape, x_train, x_test, y_train, y_test = get_data(dataset)\n",
    "    genetic = GeneticOperations()\n",
    "    networks = genetic.create_population(population)\n",
    "\n",
    "    avg_fitness_across_generations = []\n",
    "    top_fitness_across_generations = []\n",
    "    \n",
    "    for i in range(generations):\n",
    "        logging.info(\"***Envolving generation %d of %d***\" %\n",
    "                     (i + 1, generations))\n",
    "\n",
    "        # Train and get accuracy for networks.\n",
    "        train_networks(networks, dataset, trainer_method)\n",
    "        \n",
    "         # Sort our final population.\n",
    "        networks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n",
    "\n",
    "        # Print out the top 5 networks.\n",
    "        print_networks(networks[:5])\n",
    "\n",
    "        win_net = networks[0]\n",
    "        num_of_layers = len(win_net.network['architecture'])\n",
    "        architecture = win_net.network['architecture']\n",
    "        activation = win_net.network['activation']\n",
    "\n",
    "        print('Comparison to MLP from sklearn:')\n",
    "        model3 = MLPClassifier(hidden_layer_sizes = architecture, activation = activation, learning_rate_init = 1, solver = 'lbfgs').fit(x_train, y_train)\n",
    "        print('train score:',model3.score(x_train, y_train))\n",
    "        print('test score:',model3.score(x_test, y_test))\n",
    "        \n",
    "        \n",
    "        # Get the average accuracy for this generation.\n",
    "        average_accuracy = get_average_accuracy(networks)\n",
    "\n",
    "        avg_fitness_across_generations.append(average_accuracy * 100)\n",
    "        top_fitness_across_generations.append(win_net.accuracy * 100)\n",
    "        \n",
    "        \n",
    "        # Print out the average accuracy each generation.\n",
    "        logging.info(\"Generation Average: %.2f%%\" % (average_accuracy * 100))\n",
    "        logging.info('-'*80)\n",
    "\n",
    "        # Evolve, except on the last iteration.\n",
    "        if i != generations - 1:\n",
    "            networks = genetic.evolve(networks)\n",
    "   \n",
    "    avg_fitness_across_generations.insert(0,0)\n",
    "    top_fitness_across_generations.insert(0,0)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(avg_fitness_across_generations, label='avg')\n",
    "    plt.plot(top_fitness_across_generations, label='top')\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel('Generation', fontsize=12)\n",
    "    ax.set_ylabel('Fitness', fontsize=12)\n",
    "    ax.set_xticks([_ for _ in range(generations + 1)])\n",
    "    ax.set_xlim(1, 10)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "            \n",
    "def print_networks(networks):\n",
    "    for network in networks:\n",
    "        network.print_network()\n",
    "\n",
    "def main():\n",
    "    generations = 10  # Number of times to evole the population.\n",
    "    population = 20  # Number of networks in each generation.\n",
    "\n",
    "    generate(generations, population, 'iris', 'BP')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## תודה רבה!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
